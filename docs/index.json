
[{"content":"My hobbies and passion are in programming, history, philosophy, and culture, just to name a few. This is my website to publish posts for the world to read. Occasionally I have programming projects, which you can check out on my GitHub. If you have questions or want to come into contact with me for any other reason, you may do so at maxwelljensen@posteo.net.\nI do a blog, which you are viewing right now, where I post about various topics from time to time. There are also these subdomains:\ndocs.maxwelljensen.eu ðŸ“˜ Documentation for my projects. bin.maxwelljensen.eu ðŸ“‹ microbin instance for easy text and file sharing. ","date":"February 2, 2025","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"February 2, 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"August 13, 2023","externalUrl":null,"permalink":"/tags/internet/","section":"Tags","summary":"","title":"Internet","type":"tags"},{"content":"The Internet is a mega entertainment complex built on top of a graveyard of meaning. Only Silicon Valley-approved content, opinions, and mechanisms may be used to do anything on the Internet. I talk a bit about how the Internet has been slowly choked out and how it is now dead.\nI am not particularly old. BBS, Usenet, MUDs and other such 1990s constructs were not part of my childhood, but I still got to explore some of the wild Internet of the early 2000s. Practically speaking, it was like entering international waters. Seemingly no rules applied, and no law held dominion. This was the case for many years, far before the start of the 21st century, although of course the Internet did not get substantially bigger until this century.\nYet, the strange thing is: the world did not explode. Children and adults alike were allowed to anonymously insult each other. Back then, kids were actually anonymous on the Internet, because they were taught by their parents not to enter white vans of strangers who offer sweets. Most of them were taught not to talk to strangers at all, as they should be. This is in contrast to today, where it is actually considered strange for kids not to display their dox everywhere they go. Where are their parents?\nTo be clear, I would never allow my children unrestricted access to the Internet, regardless of whether it would be the 2003 or 2023 Internet. Internet usage is inherently anti-social, or asocial at the very best, which means it is unsuitable for children. Even if that were not the case, the fact alone that pornography is legal and can be readily accessed on the Internet should unilaterally place the most severe restrictions on Internet access to children. There should be no compromise or even discussion on this.\nRegardless, my parents were uninformed about the dangers of the Internet, so I had largely unrestricted access to it. Although this was always a bad idea, my time was probably the last window where you could use the Internet with zero brakes on your consumption without coming out as a mind-melted husk of a human at the end. You\u0026rsquo;ll see what I mean in a moment. The old Internet, compared to now, was barely commercialised. \u0026ldquo;Algorithms,\u0026rdquo; \u0026ldquo;search engine optimisations,\u0026rdquo; \u0026ldquo;ad revenue,\u0026rdquo; \u0026ldquo;social media,\u0026rdquo; and other cornerstones of current Internet were only in their infancy, and I bailed out just before they started taking shape.\nOld Internet was characterised by comedy and exploration. You could see expressions of people from all around the world on Newgrounds, Albino Black Sheep, or their own websites. They did not need to censor themselves. Companies barely even filed DMCA complaints, even though large amounts of that content used copyrighted material. Again: the world did not explode. Did these companies go bankrupt from all this heinous copyright infringement? You were witnessing real people and their real passion for real things. Exploring further only got you more and more unique experiences of what people found meaningful in life. Granted, most of it was 1980s to 2000s American pop culture tripe, but you get the point.\nThe shift # Compare this to today where copyright infringement and \u0026ldquo;family unfriendly\u0026rdquo; content is very aggressively persecuted. This is because Google, Facebook, and many others are founding their business on revenue from advertising on the Internet. In order to do that, they need to carve out in the corpse of the old Internet a more sterile environment. One where you may post content that advertisers will not find objectionable. American advertisers, to be clear. This is a colonial venture and the natives don\u0026rsquo;t get a say in how the colony is run, obviously. If you have, for example, Catholic sensibilities then those shall not be respected, because Silicon Valley is run by the rootless and the disrespectful.\nYou might be tempted to say: \u0026ldquo;Well, why not just search for meaningful content then?\u0026rdquo; The simple answer to that is that it is practically impossible, because all search engines are not driven by accuracy for your search, but for presenting the highest bidder for your trade offer. What, you are not looking to buy anything? Here\u0026rsquo;s one hundred results that are all about selling you useless rubbish anyway, which may or may not even exist (scam). It is also possible that the results you are after are filtered, because they might be not friendly for advertisers. Even searching for the most rudimentary repair aspects or part information for your car is impossible. You will get all worthless results of aggressively optimised websites that will make sure to override any search terms as soon as you mention the word \u0026ldquo;car\u0026rdquo; or \u0026ldquo;auto\u0026rdquo;.\nThe carving # Either way, even if search engines actually worked, meaning they were search engines and not advertiser engines, there is still one fundamental issue. The issue is that nobody makes their own websites in the first place. This is by design, which you may find to be a surprising statement, but it makes more sense the more you think about it.\nGoogle\u0026rsquo;s main instrument in carving out large parts of the Internet for themselves as well as their cronies in Silicon Valley was their dominance with Chromium, which is the engine that drives Google Chrome. Through Chromium, they started aggressively expanding the CSS and JavaScript specifications. They would pile up more and more standards to \u0026ldquo;help\u0026rdquo; with delivering more and more advanced content through the Internet. This is a lie, of course. The truth is that it ensures that no competitor to Chromium will ever exist. Given that web browsers have attained the complexity of an operating system by now, it means that Google is effectively in control of how content on the Internet can be delivered to other Internet users. Even Microsoft, infamous for doing the same exact thing with Internet Explorer, could not withstand this bombardment and eventually changed Edge\u0026rsquo;s engine for Chromium. It was more convenient than keeping up with Google\u0026rsquo;s standards as well as developing their own.\nThis is why nobody really sets up personal websites anymore. The days of simple HTML websites are long gone, and even CSS is barely comprehensible unless you spend hours unraveling the mess. Anything more complex than text and images on a page requires expert knowledge of five specifications, or a crappy, slow, proprietary, poorly coded pile of crap framework that only marginally accomplishes its intended goal. I use Zola Hugo to build these pages, but it is still something that your dad is more than likely not going to figure out how to use. You only have Google to thank for this.\nThis is just one example of how Silicon Valley companies carved out the Internet in their own image. This is how they turned it into a mega entertainment complex. Each of the other FAANG companies found their own area and dominate it ruthlessly. This is clearest illustrated with the following graph:\nYou can probably guess that this was not the situation in early 2000s, let alone 1990s. Even the data shows that the Internet is all the same. I was going to put up a different illustration that I saw before, but I could not find it, because search engines don\u0026rsquo;t really work anymore. Go figure.\nThe algorithms and their consequences # Though the development of commercialised Internet was largely uninteresting, in much the same way as watching an animal starve to death in the forest is uninteresting, one thing was truly revolutionary in the most revolting way possible. That would be the rise of TikTok. On its face it does appear to be yet another (anti-)social media platform, but its innocuous appearance truly belies its demonic nature.\nYou see, TikTok is a Trojan horse from China. Its weapon is not a conventional one, but a psychological one. To understand how that is, we should look at how algorithms in western platforms work. As you should know by now â€“ or at least get the gist of â€“ content on current Internet is not made by humans. That is, the stuff you get to see is carefully curated by an algorithm that tries its best to see what will get the most ad revenue for Google, Facebook, or whoever. The thing with that, though, is that the end-goal is profit. Yes, it does destroy feeble minds. It is sterile, malformed, ugly, but ultimately the single-mindedness behind it is profit.\nThe Chinese government does not have the same goals. They are explicitly setting out for world domination. TikTok makes use of the same concept of \u0026ldquo;algorithms\u0026rdquo; as they are implemented in modern Internet platforms, but not to make profit. Instead, their goal is to utterly demoralise and destroy western children, in order to destroy the west as a whole. To this end, TikTok presents content that releases the highest amount of dopamine in the shortest possible amount of time. For children in early development, this has life-changing consequences.\nTo see concrete, direct examples of what I am talking about, I encourage you to watch this video where Jabroni Mike runs an immersive stream while using TikTok in the way it was intended to be used. The most prominent example of TikTok\u0026rsquo;s mind-melting capabilities is the phenomenon dubbed \u0026ldquo;NPC streaming\u0026rdquo;, where people stand in front of a camera for hours, and all they do is act out \u0026ldquo;NPC animations\u0026rdquo;. These animations can be triggered by donating small amounts of money. The streamer who does these acts is typically a whorishly dressed woman, although even non-sexually dressed men are finding success in this trend.\nTo functional, rational people this might seem like an innocuous activity, but think about it for a second. Would you be interested to look at a woman say \u0026ldquo;Mmm, ice cream so good\u0026rdquo; or \u0026ldquo;Balloon, pop-pop-pop,\u0026rdquo; while making weird gestures, for even a second? No? Because that is all they do for hours on end. What if I told you these streamers get thousands of dollars per hour, when a single \u0026ldquo;animation\u0026rdquo; costs less than one dollar. These people are earning close to a dollar per second.\nThis is because these interactions are actually viewed as something meaningful. If you are familiar with the phenomenon of socially alienated men who donate money to scantily clad, inappropriate women on Twitch â€“ in hopes that they can start a social relationship with a woman â€“ this is that. It is that, but on an even more basal level. A level so basic it is extremely difficult to understand for someone who has not been thoroughly demoralised by this Chinese contraption already. You see, donating money to your favourite e-prostitute on Twitch and attaching formulated text with the donation is far too much work, and waiting for her to read out the message takes too long. With TikTok, you can shorten the process by clicking an emoji, and within a second she responds with \u0026ldquo;Mmm, ice cream so good.\u0026rdquo; If you think this sounds like psychobabble, you would not be alone, but this is the truth of the situation.\nIt is difficult to put into words what I mean, so I recommend watching this brief video to begin grasping the severity of the brain damage that our youth is suffering from TikTok. In that video, there are several videos next to each other:\nOne of a Dark Souls playthrough One of corn being dropped into a corn silo, with sound One of Subway Surfers playthrough The actual video related to the title, of Family Guy, taking up less than one-fifth of the video\u0026rsquo;s screen estate The reason for this arrangement is that watching a ten-second clip of Family Guy requires too much focus. Yes. This is the result of unrestricted access to TikTok. Your dopamine receptors are rapidly decimated, to the point where you cannot watch a ten-second Family Guy clip without needing to shift your attention to some other dopamine-releasing content at the same time. This is what your children are reduced to if you expose them to TikTok. Keep in mind that Silicon Valley platforms are not any different. The company behind TikTok just perfected the formula, and saw the potential to use it as a weapon against the government\u0026rsquo;s enemies.\nIf for you are still not convinced that TikTok is a Chinese weapon, then consider the fact that TikTok is not available in China.\nSleepwalking off a cliff # Yet, even as the current Internet is being weaponised by our mortal enemies, the western reaction to the depravity and destructiveness of the Internet is wholly lukewarm. I am met with passive hostility for merely suggesting that 5 year-olds should not have tablets, when someone asks for recommendations on hardware to buy their children who barely can walk. University of Oslo\u0026rsquo;s humanities department as always comes with the most inaccurate assessments of the matter, with Vilde Schanke Sundet saying that \u0026ldquo;People are just willing to look at weird stuff, that is the banal explanation\u0026rdquo;. Her specialty is \u0026ldquo;media research\u0026rdquo;, yet can\u0026rsquo;t spot a Chinese weaponised social media in front of her nose. This is deeply distressing, as she is unfortunately not the only one standing in utter apathy.\nYouTube, Facebook, and other Silicon Valley corporations immediately went onto copying TikTok, by releasing their own \u0026ldquo;shorts\u0026rdquo; features, hastily tacked on existing platforms, despite how poorly they integrate with the existing features. Silicon Valley cannot stomach a Chinese competitor on their territory, but of course this is not because they have any moral qualms about it being a weapon. Their only problem is that TikTok did not ask their permission to play on their turf, and is even taking money without sharing some with them. In their minds, this is unacceptable.\nThe United States federal government is taking measures to ban TikTok from its country on the basis that it is, well, a weapon meant to destroy United States and its vassals. Update: Trump overturned the ban. However, people will continue to not see the problems with Internet itself. When Ronnie McNutt killed himself on stream, the footage of his grizzly suicide was spread throughout TikTok. In a vile, deeply evil way, those videos were masked for unsuspecting children to view, thoroughly traumatising them. Yet, the reaction from parents was not: \u0026ldquo;Maybe I should have done a better job raising my own children.\u0026rdquo; Instead, it was: \u0026ldquo;TikTok should have better moderation!\u0026rdquo;\nWe will see the consequences of this in around twenty years, when these children grow up. Can they connect two pieces of pipe together without needing to watch a Subway Surfers playthrough on the side?\nDead Internet # Things will continue as always with the Internet, because the Internet is far too valuable for Silicon Valley. Regardless of how sorry of a shape it turns out in, they will always be there to make sure it is within their control.\nNearly none of the Internet is used for its original intended purpose, namely as an organic, ever-evolving repository of knowledge. On average, fewer kids born this century know how to change the tyre on a car compared to those born last century, even those born in 1950s. Those people were not raised with the Internet, yet they know more about basic things to help themselves. They are less dumb than people born in the Information Age. This was the real power of the Internet. It empowered the individual, and destroyed superfluous institutions. Silicon Valley has thoroughly overturned this primary purpose, which is where we are now. A bland, gray complex, where you are only allowed to be happy, and consume the next product.\nAs a result, the Internet has vastly outgrown its own scope as well. Where previously the Internet was largely for nerds, and was associated with nerds, it is now the staple of a large chunk of the western world. Previously, online dating was for losers, now Tinder is the norm for many demographics. This is not at all an organic growth. It\u0026rsquo;s entirely driven by the world\u0026rsquo;s largest corporations, which makes them a lot of money, but hurts the people immensely.\nSome people hypothesise, and I agree, that the Internet will become \u0026ldquo;dead Internet\u0026rdquo;. Specifically that the Internet will at some point become so automated and thoroughly hollowed out, that people will be the lesser actors in its commercial activity. At some point, it will just be algorithms talking to algorithms, with occasional input from actual humans. The more I look at the Internet, the truer it seems. Everything seems to point towards that, but the Internet is already dead to me. There is no returning from its current state, really. I worry more about what it is going to do to the general public in the future, especially our kids.\n","date":"August 13, 2023","externalUrl":null,"permalink":"/posts/internet_death/","section":"Posts","summary":"","title":"Internet Death","type":"post"},{"content":"","date":"August 13, 2023","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"December 12, 2022","externalUrl":null,"permalink":"/tags/programming/","section":"Tags","summary":"","title":"Programming","type":"tags"},{"content":"There are a lot of programming languages, but often they are talked of in terms of what realistic applications they have in the job market. Seldom is there prose about their quality as such; independent of their popularity and application. Here\u0026rsquo;s some of my thoughts.\nQuality versus utility # As most software engineers know, there is not really any correlation between the quality of a language and its popularity. There is however a correlation between popularity and utility. Python might not be the best language ever made, but any design flaws it has are offset, in the eyes of most, by the fact that it has libraries for everything. Why? Because it is in top three most popular languages, somewhere around C and Java. Therefore any issue one might encounter probably already has a complete solution in the form of a third-party library. This means that Python has extremely high utility, even if there are design issues with the language that can get in the way of common usage; while writing code.\nJava is an even better example of this, as it is demonstrably one of the most incompetently designed languages in common use. Some people would probably argue it is the worst, although I do not have personal experience with it to make that much of a bold statement. From my research, however, I can tell Java is terrible and should be avoided if possible. Not the least because the company behind it, Oracle, is possibly one of the most predatory companies on the planet, and will siphon astronomical amounts of funds from any company that uses any of their Java virtualisation technologies in any capacity.\nStill, quality of Java and even its big vendor are entirely irrelevant, and Java continues to be one of the most widely used programming languages. Why is that? Well, the answer is rather simple and is applicable to many other widely used programming languages: clout of the past. To turn a rather long story short: Java (not under Oracle at the time) was taking the software engineering world by storm, as a platform-independent alternative to C and C++. Most notable marketing gimmick was the audacious claim \u0026ldquo;write once, run anywhere\u0026rdquo;. It was also riding a then-trendy fad of object-oriented programming as being the king solution to every programming problem. Of course, as we found out quite a while ago, object-oriented programming is not a be-all and end-all solution, and Java was not even that great at implementing it to begin with, especially when compared to Python, that does everything Java ostensibly does. Regardless, the driving force was not quality of the language. It was the extensive marketing behind it, and it was sold to managers, not software engineers. Whether software engineers liked it or not, managers said Java was the new company tool of choice, and they had to put up with it. The language remains popular, because, even if aforementiomed managers became disillusioned, which they most likely did, as they saw that company bottom line remained largely unaffected, they were now stuck with Java infrastructure. As with almost anything else, it is easier to build something than to replace existing systems. This is where Oracle gets you with astronomical bills that nearly bankrupt any company, but that is veering off topic.\nSimilar story applies to programming languages like C# or Swift, except instead of a marketing force driving its popularity, it is the fact that C# is the premier solution for programming software for Windows. Same with Swift, but for macOS. Since nearly everyone uses Windows and macOS, C# and Swift are widely used as well, and Swift is not even that difficult to use outside of the macOS ecosystem. Surprising, considering it\u0026rsquo;s an Apple product.\nIn short, most programming languages are popular not because of their design merits, but because they had some success in the past that forces their use today. Even better examples than Java of this are Ada, COBOL, and especially JavaScript. Although JavaScript is not old like Ada or COBOL, it is exclusively an artifact of the early Internet, and it shows that it was made in two weeks by an overworked engineer at Mozilla. Alternatively, programming languages are popular by mandate of companies that run the most popular operating systems, such as Microsoft with C# or Apple with Swift.\nLogically, the converse is true: there are many great programming languages with outstanding design characteristics, but \u0026ldquo;nobody\u0026rdquo; uses them, rendering them useless. It\u0026rsquo;s a chicken and egg problem: nobody uses them because nobody uses them, and because they don\u0026rsquo;t have abundant libraries for solving common problems, because nobody uses them. You get the idea. Most languages do not ever get past the hobby stage for this reason. One of the languages I will give my thoughts on sort of fits into this category. Whenever there is a major problem in the IT industry, the first available solution is what becomes the irreplacable solution. Those solutions become irreplacable, because, as alluded to earlier, systems are much more easily built than replaced outright. Python was not particularly popular until it was found to be the \u0026ldquo;killer app\u0026rdquo; for prototyping in STEM fields.\nEither way, no matter how you frame the situation, quality of a language itself and its utility do not go hand in hand. In my eyes, this is a big reason why there is a larger entry barrier than necessary to software engineering. Nobody new to software engineering needs to learn Java or JavaScript, but because these languages are disproportionately popular, newcomers might be under the very mistaken impression that somehow they are representative of quality. They are not. The languages I will talk about will be described in terms of quality, and which ones are good for newcomers.\nGood programming languages # To begin with, I will look at some programming languages that I consider to be good. They appear in no particular order, but any languages I will mention I had personal extensive experience with, and do not base it off hearsay from other sources of information.\nRust # Rust appears kind of scary, and it somewhat is. Linus Torvalds said that Rust was really complex, arguing that C is a lot simpler. The Rust compiler is certainly a beast, throwing errors at you at seemingly every new line you write. To begin with, yes, it is absolutely unforgiving and gruellingly difficult for a beginner. The learning curve is infamously steep, but, once you become acquainted with the compiler, you start to realise that it is basically guiding you how to write properly imperative software.\nRust is intended for systems programming, and it is indeed fast. In some cases faster than C and C++. What might be surprising is that it is easy enough to use for even the simplest scripts, once you get past the initial learning barrier. Other than hardcore programmers like Terry A. Davis or Chris Sawyer, nobody would really want to use C or even C++ to program everything. If system administrators need a script, they will naturally resort to either Bash or Python, since the machine-level mechanisms are much more abstracted away, reducing the cognitive workload. Rust, however, is sufficiently high-level that it might be not much of a migraine to get something simple in it going. This would depend largely on the person, of course, but Rust is unmistakably better than C and C++ in several domains, with no sacrifice of raw efficiency.\nWhile in C and C++ memory management is manual, Rust utilises a unique mechanism known as the \u0026ldquo;borrow checker\u0026rdquo;. Although it is the main source of compiler throwing errors at you at every line, it means that the compiler is able to reason about the safety of your program at compile time. C and C++ compilers make exactly zero guarantees about the safety of your code at compile time, and you have to write systems checking the correctness of your program yourself. Rust, on the contrary, eliminates entire categories of security vulnerabilities and memory errors at compile time. With the exception of writing code in an unsafe { ... } block, you simply cannot compile a program that would produce memory insecurities: buffer overflows, buffer over-reads, null pointer dereferences, double frees, invalid frees, and so on. It will all be a compiler error if your code contains behaviour that would lead to that.\nA question you might be asking yourself: why bother learning Rust if it\u0026rsquo;s so hard and low-level? The answer is really rather simple: you learn how computers work at (almost) the most foundational level. Although Python is markedly easier to start off with, it doesn\u0026rsquo;t teach you how computers work. Because it doesn\u0026rsquo;t teach you how computers work, it also doesn\u0026rsquo;t give you a reference point for why certain programming practices exist. Not always, but most programming practices exist for efficiency and clarity. Sometimes efficient code is also clear code. Using \u0026ldquo;varargs\u0026rdquo; works well in Python because of duck typing, but in many other programming languages, particularly strictly typed ones, it is a bad idea or sometimes even impossible due to compiler restrictions. Using lists is almost always the better alternative, but because Python strongly depends on and encourages duck typing, these ideas will escape all newcomers to software engineering that choose Python as their first language.\nAdditionally, the Rust compiler is so sophisticated that it gives you specific errors about issues in your code, like so:\n5 | let scores = inputs().iter().map(|(a, b)| { | ^^^^^^^^ creates a temporary which is freed while still in use 6 | a + b 7 | }); | - temporary value is freed at the end of this statement 8 | println!(\u0026#34;{}\u0026#34;, scores.sum::\u0026lt;i32\u0026gt;()); | ------ borrow later used here help: consider using a `let` binding to create a longer lived value | 5 ~ let binding = inputs(); 6 ~ let scores = binding.iter().map(|(a, b)| { | For more information about this error, try `rustc --explain E0716`. Sometimes, as in the error message above, the compiler even gives you a potential solution to the problem. The Rust compiler is very smart, and in a lot of ways can act as a guide for you in learning how low-level imperative programming works. The Python environment is nowhere near as smart and, for a language priding itself on being beginner friendly, it oftentimes outputs obtuse error messages that are not at all obvious without looking them up on the Internet.\nIt is worth learning Rust, even if you figure out the compiler and still think the cognitive load is too big. You would get a lot out of the experience. You would get a far greater appreciation of what goes on \u0026ldquo;beneath the hood\u0026rdquo; of a computer program, an experience which is severely lacking in today\u0026rsquo;s IT world. It\u0026rsquo;s one of the big reasons behind why Electron is deemed an acceptable solution in any domain of general computing whatsoever, even though it is demonstrably one of the worst software frameworks to ever exist. No, 275 MB for an executable that prints \u0026ldquo;Hello, world!\u0026rdquo; is not acceptable software design. It\u0026rsquo;s software equivalent of cancer, so why would you want that on your computer? This is why I think Rust is important: it takes C++ into the 21st century, but without sacrificing performance, and therefore is a viable tool for teaching people how computers work. Tech illiteracy in software engineering is actually staggering, and more people need to see Rust, so that they can see the error of their ways.\nGo # Although often people compare Rust to Go, Go is not a systems programming language. Rather, it is Google\u0026rsquo;s in-house solution for Google problems, but has been open-source for a while now, with explosive popularity, due to its big backer.\nWhat are Google problems, then? That would be cloud and other networking solutions. Go is geared towards that in its principal design. Easy multi-threading, easy concurrency, garbage collection for development brevity, very simple ruleset, and designed by one of the main inspirations of C, Ken Thompson. The language is explicitly designed to be as close as possible to C, but garbage collected; cognitive load significantly lessened during development. It even supports generics, unlike C. Despite being garbage collected, it is not that much slower than the other top languages. Given that it compiles dependency-free binaries, like Rust, Go is excellent not just in the domain of networking, but as a general computing solution. Where performance is not of paramount importance, Go shines, and many programs that I use on a daily basis have been developed with it:\nfzf - fuzzy search finder, which I use in my Neovim config for any file indexing. gitea - how I used to host a web-facing git instance. lazygit - more sane git management. croc - trivial transfer between machines on the same LAN. For a programming language primarily designed to solve Google cloud problems, it does a good job at most of everything else. Here\u0026rsquo;s an example of a program that sorts strings and integers:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sort\u0026#34; ) func main() { strs := []string{\u0026#34;c\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;} sort.Strings(strs) fmt.Println(\u0026#34;Strings:\u0026#34;, strs) ints := []int{7, 2, 4} sort.Ints(ints) fmt.Println(\u0026#34;Ints: \u0026#34;, ints) s := sort.IntsAreSorted(ints) fmt.Println(\u0026#34;Sorted: \u0026#34;, s) } With garbage collection, type inference, built-in error interface, generics, closures, less verbose for-loops, and many other small features add up to a significantly more concise imperative language, without complete sacrifice of performance and ability to make dependency-free binaries. That is why the above code is quite concise, compared to C and similar languages.\nNim # Nim is a powerful beast. It is more than likely the most feature-rich programming language I am aware of.\nCompiles dependency-free binaries. Cross-compiles to most major platforms, even Nintendo Switch. Is garbage-collected, but has performance very near C and C++, without resorting to manual memory management! Easy, built-in multi-threading and concurrency tools. Strictly typed with compile-time type checks. Compile-time function evaluation. Object-oriented faculties, including inheritance and mutually recursive types. Transpiles to C, C++, and JavaScript if needed. Is compiled in itself, and can be metaprogrammed without restriction. Syntax strongly inspired by Python; no curly brackets needed. Syntax is extremely concise thanks to solid type inference and extensive syntactic sugar. \u0026hellip; a lot more. Here\u0026rsquo;s an example taken from Nim\u0026rsquo;s official website:\nimport std/strformat type Person = object name: string age: Natural # Ensures the age is positive let people = [ Person(name: \u0026#34;John\u0026#34;, age: 45), Person(name: \u0026#34;Kate\u0026#34;, age: 30) ] for person in people: # Type-safe string interpolation, # evaluated at compile time. echo(fmt\u0026#34;{person.name} is {person.age} years old\u0026#34;) # Thanks to Nim\u0026#39;s \u0026#39;iterator\u0026#39; and \u0026#39;yield\u0026#39; constructs, # iterators are as easy to write as ordinary # functions. They are compiled to inline loops. iterator oddNumbers[Idx, T](a: array[Idx, T]): T = for x in a: if x mod 2 == 1: yield x for odd in oddNumbers([3, 6, 9, 12, 15, 18]): echo odd # Use Nim\u0026#39;s macro system to transform a dense # data-centric description of x86 instructions # into lookup tables that are used by # assemblers and JITs. import macros, strutils macro toLookupTable(data: static[string]): untyped = result = newTree(nnkBracket) for w in data.split(\u0026#39;;\u0026#39;): result.add newLit(w) const data = \u0026#34;mov;btc;cli;xor\u0026#34; opcodes = toLookupTable(data) for o in opcodes: echo o How all of these features are implemented without markedly impacting performance is unknown to me. In all technical aspects it is an impressive language. As far as imperative languages go, I consider it to be the most sophisticated, advanced, yet pleasant language to program in. Many languages implement several of the aforementioned features: Python, C#, Swift, Go, and many others. None of them have all of these features, however, which is what distinguishes Nim from any other that I have seen.\nI had so much joy programming in Nim that they led me to my first ever minimally viable projects: nimjack and nimchain. Before these, I would play around with Python, but nothing about Python would really stick with me. It had overwhelming complexity, obscure bugs that make no sense, far too many ways to do a single common task, and more. It was an unpleasant experience for someone to just start with. Nim has a ton of features, but I always felt like there was only one, sometimes two, logical way of solving a logical problem. This is where I feel like Python and my other \u0026ldquo;good programming languages\u0026rdquo; list diverge significantly.\nThe only issue with Nim that is going to make it an unrealistic option in most environments is the fact that it is relatively unknown; unpopular. There is progressively more awareness surrounding it, if slowly. Latest uptick was a YouTube video released by Fireship, a substantially large channel about programming, titled \u0026ldquo;Nim in 100 Seconds\u0026rdquo;. According to comments under the video, Nim has found its way into ethical hacking, and in new startup companies. That being said, it is still vastly less popular than Rust and Go, which are already only moderately popular when compared to Python, C, and C++. Nevertheless, the merits of Nim cannot be overstated, and I hope it becomes a standard in the future for programming. It puts the \u0026ldquo;multi\u0026rdquo; in \u0026ldquo;multi-paradigm programming language\u0026rdquo; like no other.\nHaskell # While the aforementioned languages are predominantly imperative, Haskell is a purely functional language. Put differently, it is not a multi-paradigm programming language. Although most multi-paradigm programming languages support functional paradigms, they are just that: support. They are not a requirement, unlike Haskell, where the only paradigm accepted is functional programming. What does that look like in practice?\nquicksortÂ ::Â (OrdÂ a)Â =\u0026gt;Â [a]Â -\u0026gt;Â [a]Â quicksortÂ []Â =Â []Â quicksortÂ (x:xs)Â =Â letÂ smallerSortedÂ =Â quicksortÂ [aÂ |Â aÂ \u0026lt;-Â xs,Â aÂ \u0026lt;=Â x]Â biggerSortedÂ =Â quicksortÂ [aÂ |Â aÂ \u0026lt;-Â xs,Â aÂ \u0026gt;Â x]Â inÂ smallerSortedÂ ++Â [x]Â ++Â biggerSortedÂ Alright, that looks pretty alien. What you are looking at is a quicksort algorithm, although technically it is not real quicksort, since data is not mutated in-place. In fact, Haskell explicitly prohibits mutation, meaning only immutable variables are allowed. The whole explanation behind above code can be found here, but the essence of the language is that you code what you want, not how you want something. This makes Haskell a declarative language, as opposed to an imperative one. You declare what the output of quicksort is, rather than what quicksort does. As you can imagine, this makes Haskell a very high-level language, but it looks nothing like Python, which is another distinctly high-level language. This is because Python is an imperative language. Compare the same algorithm in Python:\ndef partition(array, begin, end): pivot = begin for i in range(begin+1, end+1): if array[i] \u0026lt;= array[begin]: pivot += 1 array[i], array[pivot] = array[pivot], array[i] array[pivot], array[begin] = array[begin], array[pivot] return pivot def quicksort(array, begin=0, end=None): if end is None: end = len(array) - 1 def _quicksort(array, begin, end): if begin \u0026gt;= end: return pivot = partition(array, begin, end) _quicksort(array, begin, pivot-1) _quicksort(array, pivot+1, end) return _quicksort(array, begin, end) Although this one is a real quicksort algorithm, since data is mutated in-place, we can clearly see that the code is a lot longer than in the Haskell example, since we have to define all the steps involved in the algorithm. We are commanding the program how to act, rather than what the output is. For this reason, the Haskell example is a lot more concise, and conciseness is where functional programming shines.\nFor me, concise code is the most important matter when writing code. Although one can alleviate the downsides of long code with proper documentation, it is best to just write code so simple that ideally documentation is unneeded. Functional programming helps with that, because then you can reason about any function only in terms of input and output. You might be tempted to say that you should keep functions and code short anyway, regardless of language. Have one function do one thing only, and do it well. I totally agree, but that is an integral tenet of functional programming. Most people in some capacity or another gravitate towards functional programming without even knowing it. Although monads and monadic I/O sound completely alien, and most software engineers never heard the word \u0026ldquo;monad\u0026rdquo; in their life before, they know what it is. They just don\u0026rsquo;t know it is called a monad, as it\u0026rsquo;s a word taken from a subdomain of mathematics known as category theory. Given that Haskell was developed by committee, explicitly for the purposes of making the all-father of functional programming, it is no surprise that Haskell terminology is going to be strange. It also doesn\u0026rsquo;t help that the committee consisted mainly of mathematicians. Even those who were not, such as Sir Simon Peyton Jones, still insisted on using mathematical terminology rather than what would become more standard in the programming sphere. After all, the language is named after Haskell Curry, who was a mathematician. I strongly recommend watching \u0026ldquo;The Haskell journey: Watt on earth were were thinking?\u0026rdquo; by Sir Simon Peyton Jones at Churchill College, University of Cambridge in 2017, for a rundown on a rather unusual development of Haskell. Sir Jones is a good presenter.\nDeclarative and functional programming # As for the language itself, it is worth learning Haskell. Much like how Rust is a very good introduction into low-level imperative programming, Haskell is, inversely, a very good introduction into what high-level declarative programming can look like. It is also purely functional, so you are forced into thinking about logical problems exclusively in those terms. It gives you a fresh perspective into programming. For me, learning Haskell was like learning programming anew; all over again. One of my friends made an interesting statement about Haskell, upon learning about it: \u0026ldquo;this is what I thought programming was before I went into Python and C#\u0026rdquo;, paraphrased. I agree. I think high-level programming languages should be a lot less like Python or JavaScript and a lot more like Haskell.\nA common response to Haskell is: if you are not able to mutate variables at all, how can you do anything? The answer is that you can do everything you can in an imperative language, just without mutation. Diesel engines don\u0026rsquo;t need spark plugs to combust fuel, and in the same vein Haskell doesn\u0026rsquo;t need mutation to do its work. The reason why Haskell does away with something so taken for granted as variable mutability is simply to prevent side-effects and keep functions pure. Why is this important? It is so that the compiler can reason about everything a function does. It is a concept known as referential transparency: the idea that any function will yield expected results every time it is run. In mathematics, that would be known as proving a statement. Therefore, a function that writes to hard drive is impure, because it is not guaranteed that every time it is run the result will be the same. The hard disk can jam, run out of power, or other issues. Granted, at a sufficiently granular level, everything in a computer is a side-effect. Writing to CPU register is a side-effect. Therefore functional purity in terms of Haskell refers to the environment of I/O versus non-I/O. Functions that depend on I/O are impure, and therefore any number, string, float, or any other type that interacts with I/O will be given the type IO a, which is a type of monad (but it is not all monads). You can never escape this monad, or any other monad, which is the whole point of monads; monadic I/O. As far as I know, no imperative language enforces such a system in their compiler/interpreter.\nUltimately all of this might sound familiar to someone who has worked with software engineering at a professional level. You do want to keep side-effects to a minimum, because referential transparency isn\u0026rsquo;t just for the benefit of the machine, it is also a benefit to the man behind the code. You do want to know what the program is doing, and referential transparency is a good start for making that happen. Well, at least if you are a good software engineer. The only difference between your coding practices and Haskell is that Haskell enforces it with its syntax and compiler.\nLastly, you might be asking yourself: what can the compiler reason about with this referential transparency? For instance, parallelising your Haskell code becomes trivial. You still have to manually specify which sections of the code are to be parallelised, because, although implicit parallelism is possible with Haskell, there are significant performance disadvantages to a strategy of parallelising everything, because at what level is the compiler supposed to parallelise workload? With unrestricted parallelisation, you can easily run into hundreds of thousands or millions of tasks, which is completely pointless on a machine with 16 or 32 cores. As threads have a certain overhead, you lose more than you gain as soon as the program becomes substantially larger than a dozen lines of code. That being said, with referential transparency you eliminate two quintessential categories of parallelisation issues: deadlocks and race conditions. At least for pure functions, but with STMs it is possible even for impure functions (I/O) with some tricks. Haskell is also very fast, with the only weakness being algorithms which are best done with in-place mutation, which Haskell currently is unable to do. Haskell is constantly worked on, however, and it is possible that some version down the line will come with a compiler so smart it knows when to do in-place mutations for maximum efficiency.\nI think it is also worthwhile to read John Carmack\u0026rsquo;s thoughts on functional programming, and this article. I don\u0026rsquo;t think it\u0026rsquo;s a coincidence that John Carmack, the genius that made DOOM possible to run on 1990s hardware, is a strong advocate for functional programming. It is interesting, considering that object-oriented programming, chiefly with C++, is widely regarded as a natural fit for video games.\nGood versus bad # Are languages like Java and JavaScript all clout and no substance? It might seem like I am giving a one-dimensional overview here with categorising aforementioned languages as good, which implies that most others are bad. Granted, yes, imperfections in Python or PHP do not make them one-dimensionally bad. They set out to do a job, and for the most part they do it well.\nI will, however, make a bold claim: most programming languages are just plain terrible. All clout and no substance. Java, JavaScript, Ruby, Scala, and many others are popular without substance to justify their popularity. They have minimal gains for all the disadvantages they come with. Most of them do not even the job they set out to do all that well. Java is bloated and incoherent. JavaScript specification is a cognitohazard. Ruby is painfully slow and does nothing that Python or PHP already don\u0026rsquo;t. Scala is just a band-aid over Java that fundamentally does nothing to address the utter dumpster fire that is the Java runtime environment. There are other languages I have reviewed, but you get the idea. When compared to existing languages, I simply do not see the value that justifies the existence of these languages. Of course, I already outlined the explanation for why the clout exists in the first paragraphs of this article. However, there are people who genuinely defend these languages as good, or even great, when that is factually incorrect. Everyone is correct in saying that Java, JavaScript, Ruby, and Scala are popular languages, but conflating that with quality is completely irrational. Quality and popularity of a language, as already briefly explained, do not go hand in hand at all. Cursory review of histories of all the languages mentioned by name in this article demonstrates this unambiguously. I do not admonish people who have to deal with these terrible languages as part of the professional career. If Java development pays, that is fine, but defence of Java as a quality language is inexcusable. I think even suggesting such things is sign of software engineering incompetence, and fundamental misunderstanding of how computers work.\nAlthough this might seem like a fatalistic assessment of the state of programming languages, I was unable to come to any other conclusion.\n","date":"December 12, 2022","externalUrl":null,"permalink":"/posts/programming_langs/","section":"Posts","summary":"","title":"Thoughts on Programming Languages","type":"post"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]